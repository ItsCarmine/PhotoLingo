{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T00:34:36.966310200Z",
     "start_time": "2023-12-03T00:34:36.950849300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import time\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),              # Resize to 256x256\n",
    "    transforms.CenterCrop(224),          # Crop to 224x224\n",
    "    transforms.ToTensor(),               # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet standards\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T19:31:48.934022900Z",
     "start_time": "2023-12-02T19:31:48.923414400Z"
    }
   },
   "id": "90b17c3f7a638757"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Load the training and testing datasets\n",
    "train_dataset = datasets.ImageFolder(root='../dataset/training', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='../dataset/testing', transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T19:31:49.526554200Z",
     "start_time": "2023-12-02T19:31:48.929032600Z"
    }
   },
   "id": "67ee3c5acc3254fc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Checking to make sure we are using our GPU instead of CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T19:31:49.593507400Z",
     "start_time": "2023-12-02T19:31:49.574045100Z"
    }
   },
   "id": "7041241c086527e9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Batch [100/1755], Loss: 0.7788\n",
      "Epoch [1/25], Batch [200/1755], Loss: 0.5523\n",
      "Epoch [1/25], Batch [300/1755], Loss: 0.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmi\\OneDrive\\Documents\\GitHub\\PhotoLingo\\venv\\Lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Batch [400/1755], Loss: 0.7806\n",
      "Epoch [1/25], Batch [500/1755], Loss: 0.4273\n",
      "Epoch [1/25], Batch [600/1755], Loss: 0.5617\n",
      "Epoch [1/25], Batch [700/1755], Loss: 0.4897\n",
      "Epoch [1/25], Batch [800/1755], Loss: 0.2220\n",
      "Epoch [1/25], Batch [900/1755], Loss: 0.3644\n",
      "Epoch [1/25], Batch [1000/1755], Loss: 0.3539\n",
      "Epoch [1/25], Batch [1100/1755], Loss: 0.5872\n",
      "Epoch [1/25], Batch [1200/1755], Loss: 0.4509\n",
      "Epoch [1/25], Batch [1300/1755], Loss: 0.2939\n",
      "Epoch [1/25], Batch [1400/1755], Loss: 0.3714\n",
      "Epoch [1/25], Batch [1500/1755], Loss: 0.2302\n",
      "Epoch [1/25], Batch [1600/1755], Loss: 0.3799\n",
      "Epoch [1/25], Batch [1700/1755], Loss: 0.2478\n",
      "Epoch [2/25], Batch [100/1755], Loss: 0.2331\n",
      "Epoch [2/25], Batch [200/1755], Loss: 0.2024\n",
      "Epoch [2/25], Batch [300/1755], Loss: 0.3390\n",
      "Epoch [2/25], Batch [400/1755], Loss: 0.2719\n",
      "Epoch [2/25], Batch [500/1755], Loss: 0.1224\n",
      "Epoch [2/25], Batch [600/1755], Loss: 0.3245\n",
      "Epoch [2/25], Batch [700/1755], Loss: 0.4523\n",
      "Epoch [2/25], Batch [800/1755], Loss: 0.3218\n",
      "Epoch [2/25], Batch [900/1755], Loss: 0.2129\n",
      "Epoch [2/25], Batch [1000/1755], Loss: 0.5407\n",
      "Epoch [2/25], Batch [1100/1755], Loss: 0.4661\n",
      "Epoch [2/25], Batch [1200/1755], Loss: 0.3440\n",
      "Epoch [2/25], Batch [1300/1755], Loss: 0.6308\n",
      "Epoch [2/25], Batch [1400/1755], Loss: 0.3544\n",
      "Epoch [2/25], Batch [1500/1755], Loss: 0.1418\n",
      "Epoch [2/25], Batch [1600/1755], Loss: 0.2578\n",
      "Epoch [2/25], Batch [1700/1755], Loss: 0.3129\n",
      "Epoch [3/25], Batch [100/1755], Loss: 0.4054\n",
      "Epoch [3/25], Batch [200/1755], Loss: 0.4006\n",
      "Epoch [3/25], Batch [300/1755], Loss: 0.1517\n",
      "Epoch [3/25], Batch [400/1755], Loss: 0.1897\n",
      "Epoch [3/25], Batch [500/1755], Loss: 0.1627\n",
      "Epoch [3/25], Batch [600/1755], Loss: 0.2068\n",
      "Epoch [3/25], Batch [700/1755], Loss: 0.2030\n",
      "Epoch [3/25], Batch [800/1755], Loss: 0.0857\n",
      "Epoch [3/25], Batch [900/1755], Loss: 0.0566\n",
      "Epoch [3/25], Batch [1000/1755], Loss: 0.4692\n",
      "Epoch [3/25], Batch [1100/1755], Loss: 0.5626\n",
      "Epoch [3/25], Batch [1200/1755], Loss: 0.1954\n",
      "Epoch [3/25], Batch [1300/1755], Loss: 0.2326\n",
      "Epoch [3/25], Batch [1400/1755], Loss: 0.2018\n",
      "Epoch [3/25], Batch [1500/1755], Loss: 0.1708\n",
      "Epoch [3/25], Batch [1600/1755], Loss: 0.4263\n",
      "Epoch [3/25], Batch [1700/1755], Loss: 0.2152\n",
      "Epoch [4/25], Batch [100/1755], Loss: 0.1015\n",
      "Epoch [4/25], Batch [200/1755], Loss: 0.0578\n",
      "Epoch [4/25], Batch [300/1755], Loss: 0.0185\n",
      "Epoch [4/25], Batch [400/1755], Loss: 0.1383\n",
      "Epoch [4/25], Batch [500/1755], Loss: 0.2835\n",
      "Epoch [4/25], Batch [600/1755], Loss: 0.0859\n",
      "Epoch [4/25], Batch [700/1755], Loss: 0.1195\n",
      "Epoch [4/25], Batch [800/1755], Loss: 0.3499\n",
      "Epoch [4/25], Batch [900/1755], Loss: 0.2539\n",
      "Epoch [4/25], Batch [1000/1755], Loss: 0.6321\n",
      "Epoch [4/25], Batch [1100/1755], Loss: 0.1298\n",
      "Epoch [4/25], Batch [1200/1755], Loss: 0.0403\n",
      "Epoch [4/25], Batch [1300/1755], Loss: 0.0273\n",
      "Epoch [4/25], Batch [1400/1755], Loss: 0.0676\n",
      "Epoch [4/25], Batch [1500/1755], Loss: 0.2197\n",
      "Epoch [4/25], Batch [1600/1755], Loss: 0.1357\n",
      "Epoch [4/25], Batch [1700/1755], Loss: 0.3325\n",
      "Epoch [5/25], Batch [100/1755], Loss: 0.0319\n",
      "Epoch [5/25], Batch [200/1755], Loss: 0.0498\n",
      "Epoch [5/25], Batch [300/1755], Loss: 0.2259\n",
      "Epoch [5/25], Batch [400/1755], Loss: 0.0976\n",
      "Epoch [5/25], Batch [500/1755], Loss: 0.0496\n",
      "Epoch [5/25], Batch [600/1755], Loss: 0.4951\n",
      "Epoch [5/25], Batch [700/1755], Loss: 0.0680\n",
      "Epoch [5/25], Batch [800/1755], Loss: 0.0583\n",
      "Epoch [5/25], Batch [900/1755], Loss: 0.2704\n",
      "Epoch [5/25], Batch [1000/1755], Loss: 0.0571\n",
      "Epoch [5/25], Batch [1100/1755], Loss: 0.0282\n",
      "Epoch [5/25], Batch [1200/1755], Loss: 0.0276\n",
      "Epoch [5/25], Batch [1300/1755], Loss: 0.0226\n",
      "Epoch [5/25], Batch [1400/1755], Loss: 0.3295\n",
      "Epoch [5/25], Batch [1500/1755], Loss: 0.1628\n",
      "Epoch [5/25], Batch [1600/1755], Loss: 0.0090\n",
      "Epoch [5/25], Batch [1700/1755], Loss: 0.1203\n",
      "Epoch [6/25], Batch [100/1755], Loss: 0.1163\n",
      "Epoch [6/25], Batch [200/1755], Loss: 0.1429\n",
      "Epoch [6/25], Batch [300/1755], Loss: 0.0560\n",
      "Epoch [6/25], Batch [400/1755], Loss: 0.0431\n",
      "Epoch [6/25], Batch [500/1755], Loss: 0.0188\n",
      "Epoch [6/25], Batch [600/1755], Loss: 0.1545\n",
      "Epoch [6/25], Batch [700/1755], Loss: 0.1173\n",
      "Epoch [6/25], Batch [800/1755], Loss: 0.0158\n",
      "Epoch [6/25], Batch [900/1755], Loss: 0.1283\n",
      "Epoch [6/25], Batch [1000/1755], Loss: 0.1393\n",
      "Epoch [6/25], Batch [1100/1755], Loss: 0.0707\n",
      "Epoch [6/25], Batch [1200/1755], Loss: 0.2670\n",
      "Epoch [6/25], Batch [1300/1755], Loss: 0.0131\n",
      "Epoch [6/25], Batch [1400/1755], Loss: 0.0810\n",
      "Epoch [6/25], Batch [1500/1755], Loss: 0.0191\n",
      "Epoch [6/25], Batch [1600/1755], Loss: 0.1273\n",
      "Epoch [6/25], Batch [1700/1755], Loss: 0.0829\n",
      "Epoch [7/25], Batch [100/1755], Loss: 0.0634\n",
      "Epoch [7/25], Batch [200/1755], Loss: 0.0935\n",
      "Epoch [7/25], Batch [300/1755], Loss: 0.0449\n",
      "Epoch [7/25], Batch [400/1755], Loss: 0.2170\n",
      "Epoch [7/25], Batch [500/1755], Loss: 0.0444\n",
      "Epoch [7/25], Batch [600/1755], Loss: 0.0885\n",
      "Epoch [7/25], Batch [700/1755], Loss: 0.1373\n",
      "Epoch [7/25], Batch [800/1755], Loss: 0.2528\n",
      "Epoch [7/25], Batch [900/1755], Loss: 0.0353\n",
      "Epoch [7/25], Batch [1000/1755], Loss: 0.1270\n",
      "Epoch [7/25], Batch [1100/1755], Loss: 0.0685\n",
      "Epoch [7/25], Batch [1200/1755], Loss: 0.1228\n",
      "Epoch [7/25], Batch [1300/1755], Loss: 0.0163\n",
      "Epoch [7/25], Batch [1400/1755], Loss: 0.0195\n",
      "Epoch [7/25], Batch [1500/1755], Loss: 0.3230\n",
      "Epoch [7/25], Batch [1600/1755], Loss: 0.1854\n",
      "Epoch [7/25], Batch [1700/1755], Loss: 0.0273\n",
      "Epoch [8/25], Batch [100/1755], Loss: 0.0552\n",
      "Epoch [8/25], Batch [200/1755], Loss: 0.0235\n",
      "Epoch [8/25], Batch [300/1755], Loss: 0.0077\n",
      "Epoch [8/25], Batch [400/1755], Loss: 0.1051\n",
      "Epoch [8/25], Batch [500/1755], Loss: 0.2075\n",
      "Epoch [8/25], Batch [600/1755], Loss: 0.0021\n",
      "Epoch [8/25], Batch [700/1755], Loss: 0.0945\n",
      "Epoch [8/25], Batch [800/1755], Loss: 0.0401\n",
      "Epoch [8/25], Batch [900/1755], Loss: 0.0010\n",
      "Epoch [8/25], Batch [1000/1755], Loss: 0.0728\n",
      "Epoch [8/25], Batch [1100/1755], Loss: 0.0026\n",
      "Epoch [8/25], Batch [1200/1755], Loss: 0.0852\n",
      "Epoch [8/25], Batch [1300/1755], Loss: 0.0676\n",
      "Epoch [8/25], Batch [1400/1755], Loss: 0.0133\n",
      "Epoch [8/25], Batch [1500/1755], Loss: 0.0507\n",
      "Epoch [8/25], Batch [1600/1755], Loss: 0.1811\n",
      "Epoch [8/25], Batch [1700/1755], Loss: 0.1102\n",
      "Epoch [9/25], Batch [100/1755], Loss: 0.0029\n",
      "Epoch [9/25], Batch [200/1755], Loss: 0.0057\n",
      "Epoch [9/25], Batch [300/1755], Loss: 0.0141\n",
      "Epoch [9/25], Batch [400/1755], Loss: 0.0366\n",
      "Epoch [9/25], Batch [500/1755], Loss: 0.0137\n",
      "Epoch [9/25], Batch [600/1755], Loss: 0.0123\n",
      "Epoch [9/25], Batch [700/1755], Loss: 0.0116\n",
      "Epoch [9/25], Batch [800/1755], Loss: 0.0658\n",
      "Epoch [9/25], Batch [900/1755], Loss: 0.0199\n",
      "Epoch [9/25], Batch [1000/1755], Loss: 0.0244\n",
      "Epoch [9/25], Batch [1100/1755], Loss: 0.0116\n",
      "Epoch [9/25], Batch [1200/1755], Loss: 0.0295\n",
      "Epoch [9/25], Batch [1300/1755], Loss: 0.0088\n",
      "Epoch [9/25], Batch [1400/1755], Loss: 0.0291\n",
      "Epoch [9/25], Batch [1500/1755], Loss: 0.0115\n",
      "Epoch [9/25], Batch [1600/1755], Loss: 0.0044\n",
      "Epoch [9/25], Batch [1700/1755], Loss: 0.0500\n",
      "Epoch [10/25], Batch [100/1755], Loss: 0.0106\n",
      "Epoch [10/25], Batch [200/1755], Loss: 0.0307\n",
      "Epoch [10/25], Batch [300/1755], Loss: 0.0179\n",
      "Epoch [10/25], Batch [400/1755], Loss: 0.0343\n",
      "Epoch [10/25], Batch [500/1755], Loss: 0.0323\n",
      "Epoch [10/25], Batch [600/1755], Loss: 0.0465\n",
      "Epoch [10/25], Batch [700/1755], Loss: 0.0058\n",
      "Epoch [10/25], Batch [800/1755], Loss: 0.0014\n",
      "Epoch [10/25], Batch [900/1755], Loss: 0.2326\n",
      "Epoch [10/25], Batch [1000/1755], Loss: 0.0243\n",
      "Epoch [10/25], Batch [1100/1755], Loss: 0.0218\n",
      "Epoch [10/25], Batch [1200/1755], Loss: 0.0192\n",
      "Epoch [10/25], Batch [1300/1755], Loss: 0.0509\n",
      "Epoch [10/25], Batch [1400/1755], Loss: 0.0092\n",
      "Epoch [10/25], Batch [1500/1755], Loss: 0.1842\n",
      "Epoch [10/25], Batch [1600/1755], Loss: 0.1072\n",
      "Epoch [10/25], Batch [1700/1755], Loss: 0.0002\n",
      "Epoch [11/25], Batch [100/1755], Loss: 0.0311\n",
      "Epoch [11/25], Batch [200/1755], Loss: 0.0115\n",
      "Epoch [11/25], Batch [300/1755], Loss: 0.0007\n",
      "Epoch [11/25], Batch [400/1755], Loss: 0.0486\n",
      "Epoch [11/25], Batch [500/1755], Loss: 0.0242\n",
      "Epoch [11/25], Batch [600/1755], Loss: 0.0105\n",
      "Epoch [11/25], Batch [700/1755], Loss: 0.0268\n",
      "Epoch [11/25], Batch [800/1755], Loss: 0.0101\n",
      "Epoch [11/25], Batch [900/1755], Loss: 0.0109\n",
      "Epoch [11/25], Batch [1000/1755], Loss: 0.0890\n",
      "Epoch [11/25], Batch [1100/1755], Loss: 0.0041\n",
      "Epoch [11/25], Batch [1200/1755], Loss: 0.2551\n",
      "Epoch [11/25], Batch [1300/1755], Loss: 0.0061\n",
      "Epoch [11/25], Batch [1400/1755], Loss: 0.0841\n",
      "Epoch [11/25], Batch [1500/1755], Loss: 0.0020\n",
      "Epoch [11/25], Batch [1600/1755], Loss: 0.0623\n",
      "Epoch [11/25], Batch [1700/1755], Loss: 0.0021\n",
      "Epoch [12/25], Batch [100/1755], Loss: 0.0026\n",
      "Epoch [12/25], Batch [200/1755], Loss: 0.0255\n",
      "Epoch [12/25], Batch [300/1755], Loss: 0.0134\n",
      "Epoch [12/25], Batch [400/1755], Loss: 0.0025\n",
      "Epoch [12/25], Batch [500/1755], Loss: 0.0523\n",
      "Epoch [12/25], Batch [600/1755], Loss: 0.0224\n",
      "Epoch [12/25], Batch [700/1755], Loss: 0.0228\n",
      "Epoch [12/25], Batch [800/1755], Loss: 0.0022\n",
      "Epoch [12/25], Batch [900/1755], Loss: 0.0024\n",
      "Epoch [12/25], Batch [1000/1755], Loss: 0.0037\n",
      "Epoch [12/25], Batch [1100/1755], Loss: 0.0043\n",
      "Epoch [12/25], Batch [1200/1755], Loss: 0.0068\n",
      "Epoch [12/25], Batch [1300/1755], Loss: 0.0099\n",
      "Epoch [12/25], Batch [1400/1755], Loss: 0.0775\n",
      "Epoch [12/25], Batch [1500/1755], Loss: 0.0052\n",
      "Epoch [12/25], Batch [1600/1755], Loss: 0.0149\n",
      "Epoch [12/25], Batch [1700/1755], Loss: 0.0012\n",
      "Epoch [13/25], Batch [100/1755], Loss: 0.0001\n",
      "Epoch [13/25], Batch [200/1755], Loss: 0.0685\n",
      "Epoch [13/25], Batch [300/1755], Loss: 0.0022\n",
      "Epoch [13/25], Batch [400/1755], Loss: 0.0277\n",
      "Epoch [13/25], Batch [500/1755], Loss: 0.1737\n",
      "Epoch [13/25], Batch [600/1755], Loss: 0.0052\n",
      "Epoch [13/25], Batch [700/1755], Loss: 0.0004\n",
      "Epoch [13/25], Batch [800/1755], Loss: 0.0120\n",
      "Epoch [13/25], Batch [900/1755], Loss: 0.0037\n",
      "Epoch [13/25], Batch [1000/1755], Loss: 0.0196\n",
      "Epoch [13/25], Batch [1100/1755], Loss: 0.0546\n",
      "Epoch [13/25], Batch [1200/1755], Loss: 0.0087\n",
      "Epoch [13/25], Batch [1300/1755], Loss: 0.1119\n",
      "Epoch [13/25], Batch [1400/1755], Loss: 0.0013\n",
      "Epoch [13/25], Batch [1500/1755], Loss: 0.0004\n",
      "Epoch [13/25], Batch [1600/1755], Loss: 0.0019\n",
      "Epoch [13/25], Batch [1700/1755], Loss: 0.0116\n",
      "Epoch [14/25], Batch [100/1755], Loss: 0.0245\n",
      "Epoch [14/25], Batch [200/1755], Loss: 0.0081\n",
      "Epoch [14/25], Batch [300/1755], Loss: 0.0059\n",
      "Epoch [14/25], Batch [400/1755], Loss: 0.0292\n",
      "Epoch [14/25], Batch [500/1755], Loss: 0.0499\n",
      "Epoch [14/25], Batch [600/1755], Loss: 0.0321\n",
      "Epoch [14/25], Batch [700/1755], Loss: 0.0531\n",
      "Epoch [14/25], Batch [800/1755], Loss: 0.0037\n",
      "Epoch [14/25], Batch [900/1755], Loss: 0.2506\n",
      "Epoch [14/25], Batch [1000/1755], Loss: 0.0038\n",
      "Epoch [14/25], Batch [1100/1755], Loss: 0.0212\n",
      "Epoch [14/25], Batch [1200/1755], Loss: 0.0001\n",
      "Epoch [14/25], Batch [1300/1755], Loss: 0.0286\n",
      "Epoch [14/25], Batch [1400/1755], Loss: 0.0082\n",
      "Epoch [14/25], Batch [1500/1755], Loss: 0.0084\n",
      "Epoch [14/25], Batch [1600/1755], Loss: 0.0242\n",
      "Epoch [14/25], Batch [1700/1755], Loss: 0.1112\n",
      "Epoch [15/25], Batch [100/1755], Loss: 0.0074\n",
      "Epoch [15/25], Batch [200/1755], Loss: 0.0032\n",
      "Epoch [15/25], Batch [300/1755], Loss: 0.0084\n",
      "Epoch [15/25], Batch [400/1755], Loss: 0.0027\n",
      "Epoch [15/25], Batch [500/1755], Loss: 0.0882\n",
      "Epoch [15/25], Batch [600/1755], Loss: 0.0002\n",
      "Epoch [15/25], Batch [700/1755], Loss: 0.0099\n",
      "Epoch [15/25], Batch [800/1755], Loss: 0.0002\n",
      "Epoch [15/25], Batch [900/1755], Loss: 0.0018\n",
      "Epoch [15/25], Batch [1000/1755], Loss: 0.0056\n",
      "Epoch [15/25], Batch [1100/1755], Loss: 0.0039\n",
      "Epoch [15/25], Batch [1200/1755], Loss: 0.0110\n",
      "Epoch [15/25], Batch [1300/1755], Loss: 0.0152\n",
      "Epoch [15/25], Batch [1400/1755], Loss: 0.0185\n",
      "Epoch [15/25], Batch [1500/1755], Loss: 0.2853\n",
      "Epoch [15/25], Batch [1600/1755], Loss: 0.0020\n",
      "Epoch [15/25], Batch [1700/1755], Loss: 0.0643\n",
      "Epoch [16/25], Batch [100/1755], Loss: 0.0068\n",
      "Epoch [16/25], Batch [200/1755], Loss: 0.1663\n",
      "Epoch [16/25], Batch [300/1755], Loss: 0.2396\n",
      "Epoch [16/25], Batch [400/1755], Loss: 0.0004\n",
      "Epoch [16/25], Batch [500/1755], Loss: 0.0051\n",
      "Epoch [16/25], Batch [600/1755], Loss: 0.0003\n",
      "Epoch [16/25], Batch [700/1755], Loss: 0.0295\n",
      "Epoch [16/25], Batch [800/1755], Loss: 0.0082\n",
      "Epoch [16/25], Batch [900/1755], Loss: 0.0440\n",
      "Epoch [16/25], Batch [1000/1755], Loss: 0.0646\n",
      "Epoch [16/25], Batch [1100/1755], Loss: 0.0244\n",
      "Epoch [16/25], Batch [1200/1755], Loss: 0.0165\n",
      "Epoch [16/25], Batch [1300/1755], Loss: 0.0020\n",
      "Epoch [16/25], Batch [1400/1755], Loss: 0.0068\n",
      "Epoch [16/25], Batch [1500/1755], Loss: 0.0004\n",
      "Epoch [16/25], Batch [1600/1755], Loss: 0.0182\n",
      "Epoch [16/25], Batch [1700/1755], Loss: 0.0005\n",
      "Epoch [17/25], Batch [100/1755], Loss: 0.0014\n",
      "Epoch [17/25], Batch [200/1755], Loss: 0.0035\n",
      "Epoch [17/25], Batch [300/1755], Loss: 0.0002\n",
      "Epoch [17/25], Batch [400/1755], Loss: 0.0001\n",
      "Epoch [17/25], Batch [500/1755], Loss: 0.0512\n",
      "Epoch [17/25], Batch [600/1755], Loss: 0.0060\n",
      "Epoch [17/25], Batch [700/1755], Loss: 0.0313\n",
      "Epoch [17/25], Batch [800/1755], Loss: 0.0378\n",
      "Epoch [17/25], Batch [900/1755], Loss: 0.1013\n",
      "Epoch [17/25], Batch [1000/1755], Loss: 0.0052\n",
      "Epoch [17/25], Batch [1100/1755], Loss: 0.0012\n",
      "Epoch [17/25], Batch [1200/1755], Loss: 0.0164\n",
      "Epoch [17/25], Batch [1300/1755], Loss: 0.0009\n",
      "Epoch [17/25], Batch [1400/1755], Loss: 0.0032\n",
      "Epoch [17/25], Batch [1500/1755], Loss: 0.1754\n",
      "Epoch [17/25], Batch [1600/1755], Loss: 0.0010\n",
      "Epoch [17/25], Batch [1700/1755], Loss: 0.0782\n",
      "Epoch [18/25], Batch [100/1755], Loss: 0.0002\n",
      "Epoch [18/25], Batch [200/1755], Loss: 0.0400\n",
      "Epoch [18/25], Batch [300/1755], Loss: 0.0141\n",
      "Epoch [18/25], Batch [400/1755], Loss: 0.0289\n",
      "Epoch [18/25], Batch [500/1755], Loss: 0.0044\n",
      "Epoch [18/25], Batch [600/1755], Loss: 0.0005\n",
      "Epoch [18/25], Batch [700/1755], Loss: 0.0008\n",
      "Epoch [18/25], Batch [800/1755], Loss: 0.0845\n",
      "Epoch [18/25], Batch [900/1755], Loss: 0.0108\n",
      "Epoch [18/25], Batch [1000/1755], Loss: 0.0108\n",
      "Epoch [18/25], Batch [1100/1755], Loss: 0.0216\n",
      "Epoch [18/25], Batch [1200/1755], Loss: 0.0228\n",
      "Epoch [18/25], Batch [1300/1755], Loss: 0.0780\n",
      "Epoch [18/25], Batch [1400/1755], Loss: 0.0046\n",
      "Epoch [18/25], Batch [1500/1755], Loss: 0.0151\n",
      "Epoch [18/25], Batch [1600/1755], Loss: 0.0084\n",
      "Epoch [18/25], Batch [1700/1755], Loss: 0.0163\n",
      "Epoch [19/25], Batch [100/1755], Loss: 0.0053\n",
      "Epoch [19/25], Batch [200/1755], Loss: 0.0089\n",
      "Epoch [19/25], Batch [300/1755], Loss: 0.0037\n",
      "Epoch [19/25], Batch [400/1755], Loss: 0.0641\n",
      "Epoch [19/25], Batch [500/1755], Loss: 0.0009\n",
      "Epoch [19/25], Batch [600/1755], Loss: 0.0002\n",
      "Epoch [19/25], Batch [700/1755], Loss: 0.0786\n",
      "Epoch [19/25], Batch [800/1755], Loss: 0.0006\n",
      "Epoch [19/25], Batch [900/1755], Loss: 0.0009\n",
      "Epoch [19/25], Batch [1000/1755], Loss: 0.0038\n",
      "Epoch [19/25], Batch [1100/1755], Loss: 0.0149\n",
      "Epoch [19/25], Batch [1200/1755], Loss: 0.0309\n",
      "Epoch [19/25], Batch [1300/1755], Loss: 0.0001\n",
      "Epoch [19/25], Batch [1400/1755], Loss: 0.0001\n",
      "Epoch [19/25], Batch [1500/1755], Loss: 0.0009\n",
      "Epoch [19/25], Batch [1600/1755], Loss: 0.0139\n",
      "Epoch [19/25], Batch [1700/1755], Loss: 0.0003\n",
      "Epoch [20/25], Batch [100/1755], Loss: 0.0006\n",
      "Epoch [20/25], Batch [200/1755], Loss: 0.0008\n",
      "Epoch [20/25], Batch [300/1755], Loss: 0.0023\n",
      "Epoch [20/25], Batch [400/1755], Loss: 0.0006\n",
      "Epoch [20/25], Batch [500/1755], Loss: 0.0050\n",
      "Epoch [20/25], Batch [600/1755], Loss: 0.0051\n",
      "Epoch [20/25], Batch [700/1755], Loss: 0.0015\n",
      "Epoch [20/25], Batch [800/1755], Loss: 0.0046\n",
      "Epoch [20/25], Batch [900/1755], Loss: 0.0064\n",
      "Epoch [20/25], Batch [1000/1755], Loss: 0.0010\n",
      "Epoch [20/25], Batch [1100/1755], Loss: 0.0700\n",
      "Epoch [20/25], Batch [1200/1755], Loss: 0.0063\n",
      "Epoch [20/25], Batch [1300/1755], Loss: 0.0044\n",
      "Epoch [20/25], Batch [1400/1755], Loss: 0.0008\n",
      "Epoch [20/25], Batch [1500/1755], Loss: 0.0325\n",
      "Epoch [20/25], Batch [1600/1755], Loss: 0.0028\n",
      "Epoch [20/25], Batch [1700/1755], Loss: 0.0037\n",
      "Epoch [21/25], Batch [100/1755], Loss: 0.1566\n",
      "Epoch [21/25], Batch [200/1755], Loss: 0.0079\n",
      "Epoch [21/25], Batch [300/1755], Loss: 0.0028\n",
      "Epoch [21/25], Batch [400/1755], Loss: 0.0041\n",
      "Epoch [21/25], Batch [500/1755], Loss: 0.0008\n",
      "Epoch [21/25], Batch [600/1755], Loss: 0.1187\n",
      "Epoch [21/25], Batch [700/1755], Loss: 0.0016\n",
      "Epoch [21/25], Batch [800/1755], Loss: 0.0016\n",
      "Epoch [21/25], Batch [900/1755], Loss: 0.0134\n",
      "Epoch [21/25], Batch [1000/1755], Loss: 0.0074\n",
      "Epoch [21/25], Batch [1100/1755], Loss: 0.0030\n",
      "Epoch [21/25], Batch [1200/1755], Loss: 0.0042\n",
      "Epoch [21/25], Batch [1300/1755], Loss: 0.0009\n",
      "Epoch [21/25], Batch [1400/1755], Loss: 0.0005\n",
      "Epoch [21/25], Batch [1500/1755], Loss: 0.0050\n",
      "Epoch [21/25], Batch [1600/1755], Loss: 0.0037\n",
      "Epoch [21/25], Batch [1700/1755], Loss: 0.0062\n",
      "Epoch [22/25], Batch [100/1755], Loss: 0.0012\n",
      "Epoch [22/25], Batch [200/1755], Loss: 0.0005\n",
      "Epoch [22/25], Batch [300/1755], Loss: 0.0460\n",
      "Epoch [22/25], Batch [400/1755], Loss: 0.0062\n",
      "Epoch [22/25], Batch [500/1755], Loss: 0.0005\n",
      "Epoch [22/25], Batch [600/1755], Loss: 0.0009\n",
      "Epoch [22/25], Batch [700/1755], Loss: 0.0083\n",
      "Epoch [22/25], Batch [800/1755], Loss: 0.0022\n",
      "Epoch [22/25], Batch [900/1755], Loss: 0.0001\n",
      "Epoch [22/25], Batch [1000/1755], Loss: 0.0003\n",
      "Epoch [22/25], Batch [1100/1755], Loss: 0.0110\n",
      "Epoch [22/25], Batch [1200/1755], Loss: 0.0235\n",
      "Epoch [22/25], Batch [1300/1755], Loss: 0.0018\n",
      "Epoch [22/25], Batch [1400/1755], Loss: 0.0023\n",
      "Epoch [22/25], Batch [1500/1755], Loss: 0.0204\n",
      "Epoch [22/25], Batch [1600/1755], Loss: 0.1173\n",
      "Epoch [22/25], Batch [1700/1755], Loss: 0.1270\n",
      "Epoch [23/25], Batch [100/1755], Loss: 0.0000\n",
      "Epoch [23/25], Batch [200/1755], Loss: 0.0000\n",
      "Epoch [23/25], Batch [300/1755], Loss: 0.0005\n",
      "Epoch [23/25], Batch [400/1755], Loss: 0.0000\n",
      "Epoch [23/25], Batch [500/1755], Loss: 0.2401\n",
      "Epoch [23/25], Batch [600/1755], Loss: 0.0019\n",
      "Epoch [23/25], Batch [700/1755], Loss: 0.0006\n",
      "Epoch [23/25], Batch [800/1755], Loss: 0.0164\n",
      "Epoch [23/25], Batch [900/1755], Loss: 0.0001\n",
      "Epoch [23/25], Batch [1000/1755], Loss: 0.0046\n",
      "Epoch [23/25], Batch [1100/1755], Loss: 0.0026\n",
      "Epoch [23/25], Batch [1200/1755], Loss: 0.0006\n",
      "Epoch [23/25], Batch [1300/1755], Loss: 0.0005\n",
      "Epoch [23/25], Batch [1400/1755], Loss: 0.0249\n",
      "Epoch [23/25], Batch [1500/1755], Loss: 0.0004\n",
      "Epoch [23/25], Batch [1600/1755], Loss: 0.0615\n",
      "Epoch [23/25], Batch [1700/1755], Loss: 0.0003\n",
      "Epoch [24/25], Batch [100/1755], Loss: 0.0001\n",
      "Epoch [24/25], Batch [200/1755], Loss: 0.0013\n",
      "Epoch [24/25], Batch [300/1755], Loss: 0.0002\n",
      "Epoch [24/25], Batch [400/1755], Loss: 0.0606\n",
      "Epoch [24/25], Batch [500/1755], Loss: 0.0146\n",
      "Epoch [24/25], Batch [600/1755], Loss: 0.0019\n",
      "Epoch [24/25], Batch [700/1755], Loss: 0.0099\n",
      "Epoch [24/25], Batch [800/1755], Loss: 0.0246\n",
      "Epoch [24/25], Batch [900/1755], Loss: 0.0026\n",
      "Epoch [24/25], Batch [1000/1755], Loss: 0.0015\n",
      "Epoch [24/25], Batch [1100/1755], Loss: 0.0001\n",
      "Epoch [24/25], Batch [1200/1755], Loss: 0.0068\n",
      "Epoch [24/25], Batch [1300/1755], Loss: 0.0070\n",
      "Epoch [24/25], Batch [1400/1755], Loss: 0.0045\n",
      "Epoch [24/25], Batch [1500/1755], Loss: 0.0200\n",
      "Epoch [24/25], Batch [1600/1755], Loss: 0.0033\n",
      "Epoch [24/25], Batch [1700/1755], Loss: 0.0004\n",
      "Epoch [25/25], Batch [100/1755], Loss: 0.0035\n",
      "Epoch [25/25], Batch [200/1755], Loss: 0.0008\n",
      "Epoch [25/25], Batch [300/1755], Loss: 0.0000\n",
      "Epoch [25/25], Batch [400/1755], Loss: 0.0001\n",
      "Epoch [25/25], Batch [500/1755], Loss: 0.0002\n",
      "Epoch [25/25], Batch [600/1755], Loss: 0.0457\n",
      "Epoch [25/25], Batch [700/1755], Loss: 0.0006\n",
      "Epoch [25/25], Batch [800/1755], Loss: 0.0751\n",
      "Epoch [25/25], Batch [900/1755], Loss: 0.0013\n",
      "Epoch [25/25], Batch [1000/1755], Loss: 0.0013\n",
      "Epoch [25/25], Batch [1100/1755], Loss: 0.0010\n",
      "Epoch [25/25], Batch [1200/1755], Loss: 0.0093\n",
      "Epoch [25/25], Batch [1300/1755], Loss: 0.0122\n",
      "Epoch [25/25], Batch [1400/1755], Loss: 0.0049\n",
      "Epoch [25/25], Batch [1500/1755], Loss: 0.0008\n",
      "Epoch [25/25], Batch [1600/1755], Loss: 0.0299\n",
      "Epoch [25/25], Batch [1700/1755], Loss: 0.0008\n",
      "Epoch [25/25] completed in 612.84 seconds - Loss: 0.0147, Acc: 0.9950\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet-101 model\n",
    "model = models.resnet18(weights=True)\n",
    "\n",
    "# Modify the last fully connected layer to match the number of classes in your dataset\n",
    "num_classes = 5 \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_batches = len(train_loader)\n",
    "        \n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if (i+1) % 100 == 0:  # Print every 100 batches\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{total_batches}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        epoch_end = time.time()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] completed in {(epoch_end - epoch_start):.2f} seconds - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, criterion, optimizer, num_epochs=25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T00:00:49.026140200Z",
     "start_time": "2023-12-02T19:31:49.574045100Z"
    }
   },
   "id": "8896f7e439907cef"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "torch.save(trained_model, '..\\models\\PhotoLingo_ResNet18_v1.pth') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T00:00:49.214308300Z",
     "start_time": "2023-12-03T00:00:49.039927Z"
    }
   },
   "id": "3f0c28e966d1dd51"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9384\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_acc = running_corrects.double() / total\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(trained_model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T00:05:55.564119200Z",
     "start_time": "2023-12-03T00:02:39.508620100Z"
    }
   },
   "id": "c5979f255c6cc42f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(directory)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.directory, self.images[idx])\n",
    "        image = Image.open(img_path).convert('RGB')  # Load as PIL Image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.images[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T00:33:38.557503500Z",
     "start_time": "2023-12-03T00:33:38.545222200Z"
    }
   },
   "id": "27f0f8f1f9ae42ba"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_dataset = UnlabeledDataset('../dataset/testing_ICDAR', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "for inputs, image_names in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    class_names = ['Arabic', 'Hindi', 'Japanese', 'Korean', 'Latin'] \n",
    "    predicted_classes = [class_names[p] for p in preds]\n",
    "    \n",
    "    for img_name, prediction in zip(image_names, predicted_classes):\n",
    "        predictions.append(f\"{img_name},{prediction}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T01:00:27.829705Z",
     "start_time": "2023-12-03T00:34:42.091722300Z"
    }
   },
   "id": "5e2c4dffb2ec1136"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "with open('predictions.txt', 'w') as f:\n",
    "    for line in predictions:\n",
    "        f.write(line + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T01:00:28.011819Z",
     "start_time": "2023-12-03T01:00:27.830703200Z"
    }
   },
   "id": "b1a15b3498364934"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d1f5bb2e6e5441a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
