{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:10:01.416419400Z",
     "start_time": "2023-12-07T03:09:57.844556700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import time\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),              # Resize to 256x256\n",
    "    transforms.CenterCrop(224),          # Crop to 224x224\n",
    "    transforms.ToTensor(),               # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet standards\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:10:01.417418200Z",
     "start_time": "2023-12-07T03:10:01.408908300Z"
    }
   },
   "id": "90b17c3f7a638757"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Load the training and testing datasets\n",
    "train_dataset = datasets.ImageFolder(root='../dataset/training', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='../dataset/testing', transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:14:11.367008800Z",
     "start_time": "2023-12-07T03:14:08.194748400Z"
    }
   },
   "id": "67ee3c5acc3254fc"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Checking to make sure we are using our GPU instead of CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:10:01.493841200Z",
     "start_time": "2023-12-07T03:10:01.418414100Z"
    }
   },
   "id": "7041241c086527e9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Batch [100/1755], Loss: 0.7788\n",
      "Epoch [1/25], Batch [200/1755], Loss: 0.5523\n",
      "Epoch [1/25], Batch [300/1755], Loss: 0.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmi\\OneDrive\\Documents\\GitHub\\PhotoLingo\\venv\\Lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Batch [400/1755], Loss: 0.7806\n",
      "Epoch [1/25], Batch [500/1755], Loss: 0.4273\n",
      "Epoch [1/25], Batch [600/1755], Loss: 0.5617\n",
      "Epoch [1/25], Batch [700/1755], Loss: 0.4897\n",
      "Epoch [1/25], Batch [800/1755], Loss: 0.2220\n",
      "Epoch [1/25], Batch [900/1755], Loss: 0.3644\n",
      "Epoch [1/25], Batch [1000/1755], Loss: 0.3539\n",
      "Epoch [1/25], Batch [1100/1755], Loss: 0.5872\n",
      "Epoch [1/25], Batch [1200/1755], Loss: 0.4509\n",
      "Epoch [1/25], Batch [1300/1755], Loss: 0.2939\n",
      "Epoch [1/25], Batch [1400/1755], Loss: 0.3714\n",
      "Epoch [1/25], Batch [1500/1755], Loss: 0.2302\n",
      "Epoch [1/25], Batch [1600/1755], Loss: 0.3799\n",
      "Epoch [1/25], Batch [1700/1755], Loss: 0.2478\n",
      "Epoch [2/25], Batch [100/1755], Loss: 0.2331\n",
      "Epoch [2/25], Batch [200/1755], Loss: 0.2024\n",
      "Epoch [2/25], Batch [300/1755], Loss: 0.3390\n",
      "Epoch [2/25], Batch [400/1755], Loss: 0.2719\n",
      "Epoch [2/25], Batch [500/1755], Loss: 0.1224\n",
      "Epoch [2/25], Batch [600/1755], Loss: 0.3245\n",
      "Epoch [2/25], Batch [700/1755], Loss: 0.4523\n",
      "Epoch [2/25], Batch [800/1755], Loss: 0.3218\n",
      "Epoch [2/25], Batch [900/1755], Loss: 0.2129\n",
      "Epoch [2/25], Batch [1000/1755], Loss: 0.5407\n",
      "Epoch [2/25], Batch [1100/1755], Loss: 0.4661\n",
      "Epoch [2/25], Batch [1200/1755], Loss: 0.3440\n",
      "Epoch [2/25], Batch [1300/1755], Loss: 0.6308\n",
      "Epoch [2/25], Batch [1400/1755], Loss: 0.3544\n",
      "Epoch [2/25], Batch [1500/1755], Loss: 0.1418\n",
      "Epoch [2/25], Batch [1600/1755], Loss: 0.2578\n",
      "Epoch [2/25], Batch [1700/1755], Loss: 0.3129\n",
      "Epoch [3/25], Batch [100/1755], Loss: 0.4054\n",
      "Epoch [3/25], Batch [200/1755], Loss: 0.4006\n",
      "Epoch [3/25], Batch [300/1755], Loss: 0.1517\n",
      "Epoch [3/25], Batch [400/1755], Loss: 0.1897\n",
      "Epoch [3/25], Batch [500/1755], Loss: 0.1627\n",
      "Epoch [3/25], Batch [600/1755], Loss: 0.2068\n",
      "Epoch [3/25], Batch [700/1755], Loss: 0.2030\n",
      "Epoch [3/25], Batch [800/1755], Loss: 0.0857\n",
      "Epoch [3/25], Batch [900/1755], Loss: 0.0566\n",
      "Epoch [3/25], Batch [1000/1755], Loss: 0.4692\n",
      "Epoch [3/25], Batch [1100/1755], Loss: 0.5626\n",
      "Epoch [3/25], Batch [1200/1755], Loss: 0.1954\n",
      "Epoch [3/25], Batch [1300/1755], Loss: 0.2326\n",
      "Epoch [3/25], Batch [1400/1755], Loss: 0.2018\n",
      "Epoch [3/25], Batch [1500/1755], Loss: 0.1708\n",
      "Epoch [3/25], Batch [1600/1755], Loss: 0.4263\n",
      "Epoch [3/25], Batch [1700/1755], Loss: 0.2152\n",
      "Epoch [4/25], Batch [100/1755], Loss: 0.1015\n",
      "Epoch [4/25], Batch [200/1755], Loss: 0.0578\n",
      "Epoch [4/25], Batch [300/1755], Loss: 0.0185\n",
      "Epoch [4/25], Batch [400/1755], Loss: 0.1383\n",
      "Epoch [4/25], Batch [500/1755], Loss: 0.2835\n",
      "Epoch [4/25], Batch [600/1755], Loss: 0.0859\n",
      "Epoch [4/25], Batch [700/1755], Loss: 0.1195\n",
      "Epoch [4/25], Batch [800/1755], Loss: 0.3499\n",
      "Epoch [4/25], Batch [900/1755], Loss: 0.2539\n",
      "Epoch [4/25], Batch [1000/1755], Loss: 0.6321\n",
      "Epoch [4/25], Batch [1100/1755], Loss: 0.1298\n",
      "Epoch [4/25], Batch [1200/1755], Loss: 0.0403\n",
      "Epoch [4/25], Batch [1300/1755], Loss: 0.0273\n",
      "Epoch [4/25], Batch [1400/1755], Loss: 0.0676\n",
      "Epoch [4/25], Batch [1500/1755], Loss: 0.2197\n",
      "Epoch [4/25], Batch [1600/1755], Loss: 0.1357\n",
      "Epoch [4/25], Batch [1700/1755], Loss: 0.3325\n",
      "Epoch [5/25], Batch [100/1755], Loss: 0.0319\n",
      "Epoch [5/25], Batch [200/1755], Loss: 0.0498\n",
      "Epoch [5/25], Batch [300/1755], Loss: 0.2259\n",
      "Epoch [5/25], Batch [400/1755], Loss: 0.0976\n",
      "Epoch [5/25], Batch [500/1755], Loss: 0.0496\n",
      "Epoch [5/25], Batch [600/1755], Loss: 0.4951\n",
      "Epoch [5/25], Batch [700/1755], Loss: 0.0680\n",
      "Epoch [5/25], Batch [800/1755], Loss: 0.0583\n",
      "Epoch [5/25], Batch [900/1755], Loss: 0.2704\n",
      "Epoch [5/25], Batch [1000/1755], Loss: 0.0571\n",
      "Epoch [5/25], Batch [1100/1755], Loss: 0.0282\n",
      "Epoch [5/25], Batch [1200/1755], Loss: 0.0276\n",
      "Epoch [5/25], Batch [1300/1755], Loss: 0.0226\n",
      "Epoch [5/25], Batch [1400/1755], Loss: 0.3295\n",
      "Epoch [5/25], Batch [1500/1755], Loss: 0.1628\n",
      "Epoch [5/25], Batch [1600/1755], Loss: 0.0090\n",
      "Epoch [5/25], Batch [1700/1755], Loss: 0.1203\n",
      "Epoch [6/25], Batch [100/1755], Loss: 0.1163\n",
      "Epoch [6/25], Batch [200/1755], Loss: 0.1429\n",
      "Epoch [6/25], Batch [300/1755], Loss: 0.0560\n",
      "Epoch [6/25], Batch [400/1755], Loss: 0.0431\n",
      "Epoch [6/25], Batch [500/1755], Loss: 0.0188\n",
      "Epoch [6/25], Batch [600/1755], Loss: 0.1545\n",
      "Epoch [6/25], Batch [700/1755], Loss: 0.1173\n",
      "Epoch [6/25], Batch [800/1755], Loss: 0.0158\n",
      "Epoch [6/25], Batch [900/1755], Loss: 0.1283\n",
      "Epoch [6/25], Batch [1000/1755], Loss: 0.1393\n",
      "Epoch [6/25], Batch [1100/1755], Loss: 0.0707\n",
      "Epoch [6/25], Batch [1200/1755], Loss: 0.2670\n",
      "Epoch [6/25], Batch [1300/1755], Loss: 0.0131\n",
      "Epoch [6/25], Batch [1400/1755], Loss: 0.0810\n",
      "Epoch [6/25], Batch [1500/1755], Loss: 0.0191\n",
      "Epoch [6/25], Batch [1600/1755], Loss: 0.1273\n",
      "Epoch [6/25], Batch [1700/1755], Loss: 0.0829\n",
      "Epoch [7/25], Batch [100/1755], Loss: 0.0634\n",
      "Epoch [7/25], Batch [200/1755], Loss: 0.0935\n",
      "Epoch [7/25], Batch [300/1755], Loss: 0.0449\n",
      "Epoch [7/25], Batch [400/1755], Loss: 0.2170\n",
      "Epoch [7/25], Batch [500/1755], Loss: 0.0444\n",
      "Epoch [7/25], Batch [600/1755], Loss: 0.0885\n",
      "Epoch [7/25], Batch [700/1755], Loss: 0.1373\n",
      "Epoch [7/25], Batch [800/1755], Loss: 0.2528\n",
      "Epoch [7/25], Batch [900/1755], Loss: 0.0353\n",
      "Epoch [7/25], Batch [1000/1755], Loss: 0.1270\n",
      "Epoch [7/25], Batch [1100/1755], Loss: 0.0685\n",
      "Epoch [7/25], Batch [1200/1755], Loss: 0.1228\n",
      "Epoch [7/25], Batch [1300/1755], Loss: 0.0163\n",
      "Epoch [7/25], Batch [1400/1755], Loss: 0.0195\n",
      "Epoch [7/25], Batch [1500/1755], Loss: 0.3230\n",
      "Epoch [7/25], Batch [1600/1755], Loss: 0.1854\n",
      "Epoch [7/25], Batch [1700/1755], Loss: 0.0273\n",
      "Epoch [8/25], Batch [100/1755], Loss: 0.0552\n",
      "Epoch [8/25], Batch [200/1755], Loss: 0.0235\n",
      "Epoch [8/25], Batch [300/1755], Loss: 0.0077\n",
      "Epoch [8/25], Batch [400/1755], Loss: 0.1051\n",
      "Epoch [8/25], Batch [500/1755], Loss: 0.2075\n",
      "Epoch [8/25], Batch [600/1755], Loss: 0.0021\n",
      "Epoch [8/25], Batch [700/1755], Loss: 0.0945\n",
      "Epoch [8/25], Batch [800/1755], Loss: 0.0401\n",
      "Epoch [8/25], Batch [900/1755], Loss: 0.0010\n",
      "Epoch [8/25], Batch [1000/1755], Loss: 0.0728\n",
      "Epoch [8/25], Batch [1100/1755], Loss: 0.0026\n",
      "Epoch [8/25], Batch [1200/1755], Loss: 0.0852\n",
      "Epoch [8/25], Batch [1300/1755], Loss: 0.0676\n",
      "Epoch [8/25], Batch [1400/1755], Loss: 0.0133\n",
      "Epoch [8/25], Batch [1500/1755], Loss: 0.0507\n",
      "Epoch [8/25], Batch [1600/1755], Loss: 0.1811\n",
      "Epoch [8/25], Batch [1700/1755], Loss: 0.1102\n",
      "Epoch [9/25], Batch [100/1755], Loss: 0.0029\n",
      "Epoch [9/25], Batch [200/1755], Loss: 0.0057\n",
      "Epoch [9/25], Batch [300/1755], Loss: 0.0141\n",
      "Epoch [9/25], Batch [400/1755], Loss: 0.0366\n",
      "Epoch [9/25], Batch [500/1755], Loss: 0.0137\n",
      "Epoch [9/25], Batch [600/1755], Loss: 0.0123\n",
      "Epoch [9/25], Batch [700/1755], Loss: 0.0116\n",
      "Epoch [9/25], Batch [800/1755], Loss: 0.0658\n",
      "Epoch [9/25], Batch [900/1755], Loss: 0.0199\n",
      "Epoch [9/25], Batch [1000/1755], Loss: 0.0244\n",
      "Epoch [9/25], Batch [1100/1755], Loss: 0.0116\n",
      "Epoch [9/25], Batch [1200/1755], Loss: 0.0295\n",
      "Epoch [9/25], Batch [1300/1755], Loss: 0.0088\n",
      "Epoch [9/25], Batch [1400/1755], Loss: 0.0291\n",
      "Epoch [9/25], Batch [1500/1755], Loss: 0.0115\n",
      "Epoch [9/25], Batch [1600/1755], Loss: 0.0044\n",
      "Epoch [9/25], Batch [1700/1755], Loss: 0.0500\n",
      "Epoch [10/25], Batch [100/1755], Loss: 0.0106\n",
      "Epoch [10/25], Batch [200/1755], Loss: 0.0307\n",
      "Epoch [10/25], Batch [300/1755], Loss: 0.0179\n",
      "Epoch [10/25], Batch [400/1755], Loss: 0.0343\n",
      "Epoch [10/25], Batch [500/1755], Loss: 0.0323\n",
      "Epoch [10/25], Batch [600/1755], Loss: 0.0465\n",
      "Epoch [10/25], Batch [700/1755], Loss: 0.0058\n",
      "Epoch [10/25], Batch [800/1755], Loss: 0.0014\n",
      "Epoch [10/25], Batch [900/1755], Loss: 0.2326\n",
      "Epoch [10/25], Batch [1000/1755], Loss: 0.0243\n",
      "Epoch [10/25], Batch [1100/1755], Loss: 0.0218\n",
      "Epoch [10/25], Batch [1200/1755], Loss: 0.0192\n",
      "Epoch [10/25], Batch [1300/1755], Loss: 0.0509\n",
      "Epoch [10/25], Batch [1400/1755], Loss: 0.0092\n",
      "Epoch [10/25], Batch [1500/1755], Loss: 0.1842\n",
      "Epoch [10/25], Batch [1600/1755], Loss: 0.1072\n",
      "Epoch [10/25], Batch [1700/1755], Loss: 0.0002\n",
      "Epoch [11/25], Batch [100/1755], Loss: 0.0311\n",
      "Epoch [11/25], Batch [200/1755], Loss: 0.0115\n",
      "Epoch [11/25], Batch [300/1755], Loss: 0.0007\n",
      "Epoch [11/25], Batch [400/1755], Loss: 0.0486\n",
      "Epoch [11/25], Batch [500/1755], Loss: 0.0242\n",
      "Epoch [11/25], Batch [600/1755], Loss: 0.0105\n",
      "Epoch [11/25], Batch [700/1755], Loss: 0.0268\n",
      "Epoch [11/25], Batch [800/1755], Loss: 0.0101\n",
      "Epoch [11/25], Batch [900/1755], Loss: 0.0109\n",
      "Epoch [11/25], Batch [1000/1755], Loss: 0.0890\n",
      "Epoch [11/25], Batch [1100/1755], Loss: 0.0041\n",
      "Epoch [11/25], Batch [1200/1755], Loss: 0.2551\n",
      "Epoch [11/25], Batch [1300/1755], Loss: 0.0061\n",
      "Epoch [11/25], Batch [1400/1755], Loss: 0.0841\n",
      "Epoch [11/25], Batch [1500/1755], Loss: 0.0020\n",
      "Epoch [11/25], Batch [1600/1755], Loss: 0.0623\n",
      "Epoch [11/25], Batch [1700/1755], Loss: 0.0021\n",
      "Epoch [12/25], Batch [100/1755], Loss: 0.0026\n",
      "Epoch [12/25], Batch [200/1755], Loss: 0.0255\n",
      "Epoch [12/25], Batch [300/1755], Loss: 0.0134\n",
      "Epoch [12/25], Batch [400/1755], Loss: 0.0025\n",
      "Epoch [12/25], Batch [500/1755], Loss: 0.0523\n",
      "Epoch [12/25], Batch [600/1755], Loss: 0.0224\n",
      "Epoch [12/25], Batch [700/1755], Loss: 0.0228\n",
      "Epoch [12/25], Batch [800/1755], Loss: 0.0022\n",
      "Epoch [12/25], Batch [900/1755], Loss: 0.0024\n",
      "Epoch [12/25], Batch [1000/1755], Loss: 0.0037\n",
      "Epoch [12/25], Batch [1100/1755], Loss: 0.0043\n",
      "Epoch [12/25], Batch [1200/1755], Loss: 0.0068\n",
      "Epoch [12/25], Batch [1300/1755], Loss: 0.0099\n",
      "Epoch [12/25], Batch [1400/1755], Loss: 0.0775\n",
      "Epoch [12/25], Batch [1500/1755], Loss: 0.0052\n",
      "Epoch [12/25], Batch [1600/1755], Loss: 0.0149\n",
      "Epoch [12/25], Batch [1700/1755], Loss: 0.0012\n",
      "Epoch [13/25], Batch [100/1755], Loss: 0.0001\n",
      "Epoch [13/25], Batch [200/1755], Loss: 0.0685\n",
      "Epoch [13/25], Batch [300/1755], Loss: 0.0022\n",
      "Epoch [13/25], Batch [400/1755], Loss: 0.0277\n",
      "Epoch [13/25], Batch [500/1755], Loss: 0.1737\n",
      "Epoch [13/25], Batch [600/1755], Loss: 0.0052\n",
      "Epoch [13/25], Batch [700/1755], Loss: 0.0004\n",
      "Epoch [13/25], Batch [800/1755], Loss: 0.0120\n",
      "Epoch [13/25], Batch [900/1755], Loss: 0.0037\n",
      "Epoch [13/25], Batch [1000/1755], Loss: 0.0196\n",
      "Epoch [13/25], Batch [1100/1755], Loss: 0.0546\n",
      "Epoch [13/25], Batch [1200/1755], Loss: 0.0087\n",
      "Epoch [13/25], Batch [1300/1755], Loss: 0.1119\n",
      "Epoch [13/25], Batch [1400/1755], Loss: 0.0013\n",
      "Epoch [13/25], Batch [1500/1755], Loss: 0.0004\n",
      "Epoch [13/25], Batch [1600/1755], Loss: 0.0019\n",
      "Epoch [13/25], Batch [1700/1755], Loss: 0.0116\n",
      "Epoch [14/25], Batch [100/1755], Loss: 0.0245\n",
      "Epoch [14/25], Batch [200/1755], Loss: 0.0081\n",
      "Epoch [14/25], Batch [300/1755], Loss: 0.0059\n",
      "Epoch [14/25], Batch [400/1755], Loss: 0.0292\n",
      "Epoch [14/25], Batch [500/1755], Loss: 0.0499\n",
      "Epoch [14/25], Batch [600/1755], Loss: 0.0321\n",
      "Epoch [14/25], Batch [700/1755], Loss: 0.0531\n",
      "Epoch [14/25], Batch [800/1755], Loss: 0.0037\n",
      "Epoch [14/25], Batch [900/1755], Loss: 0.2506\n",
      "Epoch [14/25], Batch [1000/1755], Loss: 0.0038\n",
      "Epoch [14/25], Batch [1100/1755], Loss: 0.0212\n",
      "Epoch [14/25], Batch [1200/1755], Loss: 0.0001\n",
      "Epoch [14/25], Batch [1300/1755], Loss: 0.0286\n",
      "Epoch [14/25], Batch [1400/1755], Loss: 0.0082\n",
      "Epoch [14/25], Batch [1500/1755], Loss: 0.0084\n",
      "Epoch [14/25], Batch [1600/1755], Loss: 0.0242\n",
      "Epoch [14/25], Batch [1700/1755], Loss: 0.1112\n",
      "Epoch [15/25], Batch [100/1755], Loss: 0.0074\n",
      "Epoch [15/25], Batch [200/1755], Loss: 0.0032\n",
      "Epoch [15/25], Batch [300/1755], Loss: 0.0084\n",
      "Epoch [15/25], Batch [400/1755], Loss: 0.0027\n",
      "Epoch [15/25], Batch [500/1755], Loss: 0.0882\n",
      "Epoch [15/25], Batch [600/1755], Loss: 0.0002\n",
      "Epoch [15/25], Batch [700/1755], Loss: 0.0099\n",
      "Epoch [15/25], Batch [800/1755], Loss: 0.0002\n",
      "Epoch [15/25], Batch [900/1755], Loss: 0.0018\n",
      "Epoch [15/25], Batch [1000/1755], Loss: 0.0056\n",
      "Epoch [15/25], Batch [1100/1755], Loss: 0.0039\n",
      "Epoch [15/25], Batch [1200/1755], Loss: 0.0110\n",
      "Epoch [15/25], Batch [1300/1755], Loss: 0.0152\n",
      "Epoch [15/25], Batch [1400/1755], Loss: 0.0185\n",
      "Epoch [15/25], Batch [1500/1755], Loss: 0.2853\n",
      "Epoch [15/25], Batch [1600/1755], Loss: 0.0020\n",
      "Epoch [15/25], Batch [1700/1755], Loss: 0.0643\n",
      "Epoch [16/25], Batch [100/1755], Loss: 0.0068\n",
      "Epoch [16/25], Batch [200/1755], Loss: 0.1663\n",
      "Epoch [16/25], Batch [300/1755], Loss: 0.2396\n",
      "Epoch [16/25], Batch [400/1755], Loss: 0.0004\n",
      "Epoch [16/25], Batch [500/1755], Loss: 0.0051\n",
      "Epoch [16/25], Batch [600/1755], Loss: 0.0003\n",
      "Epoch [16/25], Batch [700/1755], Loss: 0.0295\n",
      "Epoch [16/25], Batch [800/1755], Loss: 0.0082\n",
      "Epoch [16/25], Batch [900/1755], Loss: 0.0440\n",
      "Epoch [16/25], Batch [1000/1755], Loss: 0.0646\n",
      "Epoch [16/25], Batch [1100/1755], Loss: 0.0244\n",
      "Epoch [16/25], Batch [1200/1755], Loss: 0.0165\n",
      "Epoch [16/25], Batch [1300/1755], Loss: 0.0020\n",
      "Epoch [16/25], Batch [1400/1755], Loss: 0.0068\n",
      "Epoch [16/25], Batch [1500/1755], Loss: 0.0004\n",
      "Epoch [16/25], Batch [1600/1755], Loss: 0.0182\n",
      "Epoch [16/25], Batch [1700/1755], Loss: 0.0005\n",
      "Epoch [17/25], Batch [100/1755], Loss: 0.0014\n",
      "Epoch [17/25], Batch [200/1755], Loss: 0.0035\n",
      "Epoch [17/25], Batch [300/1755], Loss: 0.0002\n",
      "Epoch [17/25], Batch [400/1755], Loss: 0.0001\n",
      "Epoch [17/25], Batch [500/1755], Loss: 0.0512\n",
      "Epoch [17/25], Batch [600/1755], Loss: 0.0060\n",
      "Epoch [17/25], Batch [700/1755], Loss: 0.0313\n",
      "Epoch [17/25], Batch [800/1755], Loss: 0.0378\n",
      "Epoch [17/25], Batch [900/1755], Loss: 0.1013\n",
      "Epoch [17/25], Batch [1000/1755], Loss: 0.0052\n",
      "Epoch [17/25], Batch [1100/1755], Loss: 0.0012\n",
      "Epoch [17/25], Batch [1200/1755], Loss: 0.0164\n",
      "Epoch [17/25], Batch [1300/1755], Loss: 0.0009\n",
      "Epoch [17/25], Batch [1400/1755], Loss: 0.0032\n",
      "Epoch [17/25], Batch [1500/1755], Loss: 0.1754\n",
      "Epoch [17/25], Batch [1600/1755], Loss: 0.0010\n",
      "Epoch [17/25], Batch [1700/1755], Loss: 0.0782\n",
      "Epoch [18/25], Batch [100/1755], Loss: 0.0002\n",
      "Epoch [18/25], Batch [200/1755], Loss: 0.0400\n",
      "Epoch [18/25], Batch [300/1755], Loss: 0.0141\n",
      "Epoch [18/25], Batch [400/1755], Loss: 0.0289\n",
      "Epoch [18/25], Batch [500/1755], Loss: 0.0044\n",
      "Epoch [18/25], Batch [600/1755], Loss: 0.0005\n",
      "Epoch [18/25], Batch [700/1755], Loss: 0.0008\n",
      "Epoch [18/25], Batch [800/1755], Loss: 0.0845\n",
      "Epoch [18/25], Batch [900/1755], Loss: 0.0108\n",
      "Epoch [18/25], Batch [1000/1755], Loss: 0.0108\n",
      "Epoch [18/25], Batch [1100/1755], Loss: 0.0216\n",
      "Epoch [18/25], Batch [1200/1755], Loss: 0.0228\n",
      "Epoch [18/25], Batch [1300/1755], Loss: 0.0780\n",
      "Epoch [18/25], Batch [1400/1755], Loss: 0.0046\n",
      "Epoch [18/25], Batch [1500/1755], Loss: 0.0151\n",
      "Epoch [18/25], Batch [1600/1755], Loss: 0.0084\n",
      "Epoch [18/25], Batch [1700/1755], Loss: 0.0163\n",
      "Epoch [19/25], Batch [100/1755], Loss: 0.0053\n",
      "Epoch [19/25], Batch [200/1755], Loss: 0.0089\n",
      "Epoch [19/25], Batch [300/1755], Loss: 0.0037\n",
      "Epoch [19/25], Batch [400/1755], Loss: 0.0641\n",
      "Epoch [19/25], Batch [500/1755], Loss: 0.0009\n",
      "Epoch [19/25], Batch [600/1755], Loss: 0.0002\n",
      "Epoch [19/25], Batch [700/1755], Loss: 0.0786\n",
      "Epoch [19/25], Batch [800/1755], Loss: 0.0006\n",
      "Epoch [19/25], Batch [900/1755], Loss: 0.0009\n",
      "Epoch [19/25], Batch [1000/1755], Loss: 0.0038\n",
      "Epoch [19/25], Batch [1100/1755], Loss: 0.0149\n",
      "Epoch [19/25], Batch [1200/1755], Loss: 0.0309\n",
      "Epoch [19/25], Batch [1300/1755], Loss: 0.0001\n",
      "Epoch [19/25], Batch [1400/1755], Loss: 0.0001\n",
      "Epoch [19/25], Batch [1500/1755], Loss: 0.0009\n",
      "Epoch [19/25], Batch [1600/1755], Loss: 0.0139\n",
      "Epoch [19/25], Batch [1700/1755], Loss: 0.0003\n",
      "Epoch [20/25], Batch [100/1755], Loss: 0.0006\n",
      "Epoch [20/25], Batch [200/1755], Loss: 0.0008\n",
      "Epoch [20/25], Batch [300/1755], Loss: 0.0023\n",
      "Epoch [20/25], Batch [400/1755], Loss: 0.0006\n",
      "Epoch [20/25], Batch [500/1755], Loss: 0.0050\n",
      "Epoch [20/25], Batch [600/1755], Loss: 0.0051\n",
      "Epoch [20/25], Batch [700/1755], Loss: 0.0015\n",
      "Epoch [20/25], Batch [800/1755], Loss: 0.0046\n",
      "Epoch [20/25], Batch [900/1755], Loss: 0.0064\n",
      "Epoch [20/25], Batch [1000/1755], Loss: 0.0010\n",
      "Epoch [20/25], Batch [1100/1755], Loss: 0.0700\n",
      "Epoch [20/25], Batch [1200/1755], Loss: 0.0063\n",
      "Epoch [20/25], Batch [1300/1755], Loss: 0.0044\n",
      "Epoch [20/25], Batch [1400/1755], Loss: 0.0008\n",
      "Epoch [20/25], Batch [1500/1755], Loss: 0.0325\n",
      "Epoch [20/25], Batch [1600/1755], Loss: 0.0028\n",
      "Epoch [20/25], Batch [1700/1755], Loss: 0.0037\n",
      "Epoch [21/25], Batch [100/1755], Loss: 0.1566\n",
      "Epoch [21/25], Batch [200/1755], Loss: 0.0079\n",
      "Epoch [21/25], Batch [300/1755], Loss: 0.0028\n",
      "Epoch [21/25], Batch [400/1755], Loss: 0.0041\n",
      "Epoch [21/25], Batch [500/1755], Loss: 0.0008\n",
      "Epoch [21/25], Batch [600/1755], Loss: 0.1187\n",
      "Epoch [21/25], Batch [700/1755], Loss: 0.0016\n",
      "Epoch [21/25], Batch [800/1755], Loss: 0.0016\n",
      "Epoch [21/25], Batch [900/1755], Loss: 0.0134\n",
      "Epoch [21/25], Batch [1000/1755], Loss: 0.0074\n",
      "Epoch [21/25], Batch [1100/1755], Loss: 0.0030\n",
      "Epoch [21/25], Batch [1200/1755], Loss: 0.0042\n",
      "Epoch [21/25], Batch [1300/1755], Loss: 0.0009\n",
      "Epoch [21/25], Batch [1400/1755], Loss: 0.0005\n",
      "Epoch [21/25], Batch [1500/1755], Loss: 0.0050\n",
      "Epoch [21/25], Batch [1600/1755], Loss: 0.0037\n",
      "Epoch [21/25], Batch [1700/1755], Loss: 0.0062\n",
      "Epoch [22/25], Batch [100/1755], Loss: 0.0012\n",
      "Epoch [22/25], Batch [200/1755], Loss: 0.0005\n",
      "Epoch [22/25], Batch [300/1755], Loss: 0.0460\n",
      "Epoch [22/25], Batch [400/1755], Loss: 0.0062\n",
      "Epoch [22/25], Batch [500/1755], Loss: 0.0005\n",
      "Epoch [22/25], Batch [600/1755], Loss: 0.0009\n",
      "Epoch [22/25], Batch [700/1755], Loss: 0.0083\n",
      "Epoch [22/25], Batch [800/1755], Loss: 0.0022\n",
      "Epoch [22/25], Batch [900/1755], Loss: 0.0001\n",
      "Epoch [22/25], Batch [1000/1755], Loss: 0.0003\n",
      "Epoch [22/25], Batch [1100/1755], Loss: 0.0110\n",
      "Epoch [22/25], Batch [1200/1755], Loss: 0.0235\n",
      "Epoch [22/25], Batch [1300/1755], Loss: 0.0018\n",
      "Epoch [22/25], Batch [1400/1755], Loss: 0.0023\n",
      "Epoch [22/25], Batch [1500/1755], Loss: 0.0204\n",
      "Epoch [22/25], Batch [1600/1755], Loss: 0.1173\n",
      "Epoch [22/25], Batch [1700/1755], Loss: 0.1270\n",
      "Epoch [23/25], Batch [100/1755], Loss: 0.0000\n",
      "Epoch [23/25], Batch [200/1755], Loss: 0.0000\n",
      "Epoch [23/25], Batch [300/1755], Loss: 0.0005\n",
      "Epoch [23/25], Batch [400/1755], Loss: 0.0000\n",
      "Epoch [23/25], Batch [500/1755], Loss: 0.2401\n",
      "Epoch [23/25], Batch [600/1755], Loss: 0.0019\n",
      "Epoch [23/25], Batch [700/1755], Loss: 0.0006\n",
      "Epoch [23/25], Batch [800/1755], Loss: 0.0164\n",
      "Epoch [23/25], Batch [900/1755], Loss: 0.0001\n",
      "Epoch [23/25], Batch [1000/1755], Loss: 0.0046\n",
      "Epoch [23/25], Batch [1100/1755], Loss: 0.0026\n",
      "Epoch [23/25], Batch [1200/1755], Loss: 0.0006\n",
      "Epoch [23/25], Batch [1300/1755], Loss: 0.0005\n",
      "Epoch [23/25], Batch [1400/1755], Loss: 0.0249\n",
      "Epoch [23/25], Batch [1500/1755], Loss: 0.0004\n",
      "Epoch [23/25], Batch [1600/1755], Loss: 0.0615\n",
      "Epoch [23/25], Batch [1700/1755], Loss: 0.0003\n",
      "Epoch [24/25], Batch [100/1755], Loss: 0.0001\n",
      "Epoch [24/25], Batch [200/1755], Loss: 0.0013\n",
      "Epoch [24/25], Batch [300/1755], Loss: 0.0002\n",
      "Epoch [24/25], Batch [400/1755], Loss: 0.0606\n",
      "Epoch [24/25], Batch [500/1755], Loss: 0.0146\n",
      "Epoch [24/25], Batch [600/1755], Loss: 0.0019\n",
      "Epoch [24/25], Batch [700/1755], Loss: 0.0099\n",
      "Epoch [24/25], Batch [800/1755], Loss: 0.0246\n",
      "Epoch [24/25], Batch [900/1755], Loss: 0.0026\n",
      "Epoch [24/25], Batch [1000/1755], Loss: 0.0015\n",
      "Epoch [24/25], Batch [1100/1755], Loss: 0.0001\n",
      "Epoch [24/25], Batch [1200/1755], Loss: 0.0068\n",
      "Epoch [24/25], Batch [1300/1755], Loss: 0.0070\n",
      "Epoch [24/25], Batch [1400/1755], Loss: 0.0045\n",
      "Epoch [24/25], Batch [1500/1755], Loss: 0.0200\n",
      "Epoch [24/25], Batch [1600/1755], Loss: 0.0033\n",
      "Epoch [24/25], Batch [1700/1755], Loss: 0.0004\n",
      "Epoch [25/25], Batch [100/1755], Loss: 0.0035\n",
      "Epoch [25/25], Batch [200/1755], Loss: 0.0008\n",
      "Epoch [25/25], Batch [300/1755], Loss: 0.0000\n",
      "Epoch [25/25], Batch [400/1755], Loss: 0.0001\n",
      "Epoch [25/25], Batch [500/1755], Loss: 0.0002\n",
      "Epoch [25/25], Batch [600/1755], Loss: 0.0457\n",
      "Epoch [25/25], Batch [700/1755], Loss: 0.0006\n",
      "Epoch [25/25], Batch [800/1755], Loss: 0.0751\n",
      "Epoch [25/25], Batch [900/1755], Loss: 0.0013\n",
      "Epoch [25/25], Batch [1000/1755], Loss: 0.0013\n",
      "Epoch [25/25], Batch [1100/1755], Loss: 0.0010\n",
      "Epoch [25/25], Batch [1200/1755], Loss: 0.0093\n",
      "Epoch [25/25], Batch [1300/1755], Loss: 0.0122\n",
      "Epoch [25/25], Batch [1400/1755], Loss: 0.0049\n",
      "Epoch [25/25], Batch [1500/1755], Loss: 0.0008\n",
      "Epoch [25/25], Batch [1600/1755], Loss: 0.0299\n",
      "Epoch [25/25], Batch [1700/1755], Loss: 0.0008\n",
      "Epoch [25/25] completed in 612.84 seconds - Loss: 0.0147, Acc: 0.9950\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet-101 model\n",
    "model = models.resnet18(weights=True)\n",
    "\n",
    "# Modify the last fully connected layer to match the number of classes in your dataset\n",
    "num_classes = 5 \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_batches = len(train_loader)\n",
    "        \n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if (i+1) % 100 == 0:  # Print every 100 batches\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{total_batches}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        epoch_end = time.time()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] completed in {(epoch_end - epoch_start):.2f} seconds - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(model, criterion, optimizer, num_epochs=25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T00:00:49.026140200Z",
     "start_time": "2023-12-02T19:31:49.574045100Z"
    }
   },
   "id": "8896f7e439907cef"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "torch.save(trained_model, '..\\models\\PhotoLingo_ResNet18_v1.pth') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T00:00:49.214308300Z",
     "start_time": "2023-12-03T00:00:49.039927Z"
    }
   },
   "id": "3f0c28e966d1dd51"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=5, bias=True)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained ResNet-101 model\n",
    "model = models.resnet18(weights=True)\n",
    "\n",
    "# Modify the last fully connected layer to match the number of classes in your dataset\n",
    "num_classes = 5 \n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:13:00.198112700Z",
     "start_time": "2023-12-07T03:12:58.979296900Z"
    }
   },
   "id": "89155fe55b2e4b7d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=5, bias=True)\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model state\n",
    "model = torch.load('../models/PhotoLingo_ResNet18_v1.pth').to(device)\n",
    "\n",
    "# Put the model in evaluation mode if you are doing inference\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:15:55.079753400Z",
     "start_time": "2023-12-07T03:15:54.978651300Z"
    }
   },
   "id": "86f36b18739ef900"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9384\n"
     ]
    }
   ],
   "source": [
    "# def evaluate_model(model, test_loader):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "# \n",
    "#     running_corrects = 0\n",
    "#     total = 0\n",
    "# \n",
    "#     with torch.no_grad():  # No need to track gradients for evaluation\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "# \n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "# \n",
    "#             running_corrects += torch.sum(preds == labels.data)\n",
    "#             total += labels.size(0)\n",
    "# \n",
    "#     test_acc = running_corrects.double() / total\n",
    "#     print(f'Test Accuracy: {test_acc:.4f}')\n",
    "# \n",
    "# # Evaluate the model\n",
    "# evaluate_model(trained_model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T00:05:55.564119200Z",
     "start_time": "2023-12-03T00:02:39.508620100Z"
    }
   },
   "id": "c5979f255c6cc42f"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(directory)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.directory, self.images[idx])\n",
    "        image = Image.open(img_path).convert('RGB')  # Load as PIL Image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.images[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:13:56.465353800Z",
     "start_time": "2023-12-07T03:13:56.449338Z"
    }
   },
   "id": "27f0f8f1f9ae42ba"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# \n",
    "# test_dataset = UnlabeledDataset('../dataset/testing_ICDAR', transform=transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "# \n",
    "# predictions = []\n",
    "# for inputs, image_names in test_loader:\n",
    "#     inputs = inputs.to(device)\n",
    "#     outputs = model(inputs)\n",
    "#     _, preds = torch.max(outputs, 1)\n",
    "#     \n",
    "#     class_names = ['Arabic', 'Hindi', 'Japanese', 'Korean', 'Latin'] \n",
    "#     predicted_classes = [class_names[p] for p in preds]\n",
    "#     \n",
    "#     for img_name, prediction in zip(image_names, predicted_classes):\n",
    "#         predictions.append(f\"{img_name},{prediction}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T01:00:27.829705Z",
     "start_time": "2023-12-03T00:34:42.091722300Z"
    }
   },
   "id": "5e2c4dffb2ec1136"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# with open('predictions.txt', 'w') as f:\n",
    "#     for line in predictions:\n",
    "#         f.write(line + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T01:00:28.011819Z",
     "start_time": "2023-12-03T01:00:27.830703200Z"
    }
   },
   "id": "b1a15b3498364934"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmi\\OneDrive\\Documents\\GitHub\\PhotoLingo\\venv\\Lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 1205     1    22    13   169]\n",
      " [    2  1079    16     8    75]\n",
      " [   12     4  1347    54   365]\n",
      " [    5     2    83  1663   283]\n",
      " [   50    18   203    98 17287]]\n",
      "Accuracy: 0.9383726728723404%\n",
      "Precision (per class): [0.94583987 0.97735507 0.80610413 0.90577342 0.95093239]\n",
      "Recall (per class): [0.85460993 0.91440678 0.75589226 0.81679764 0.97910059]\n",
      "F1 Score (per class): [0.89791356 0.94483363 0.78019114 0.8589876  0.96481094]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# No gradients needed for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.extend(predicted.cpu().numpy())  # Append batch predictions\n",
    "        y_true.extend(labels.cpu().numpy())  # Append true labels\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate precision, recall, F1-score and support for each class\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Accuracy: {accuracy}%')\n",
    "print(f'Precision (per class): {precision}')\n",
    "print(f'Recall (per class): {recall}')\n",
    "print(f'F1 Score (per class): {f1_score}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:20:20.815857700Z",
     "start_time": "2023-12-07T03:16:30.511948300Z"
    }
   },
   "id": "d1f5bb2e6e5441a0"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity (per class): [0.99695418 0.99890753 0.98545911 0.99214636 0.860799  ]\n",
      "Specificity (avg): 0.966853237866709\n"
     ]
    }
   ],
   "source": [
    "# Corrected specificity calculation for each class\n",
    "specificity = []\n",
    "num_classes = len(conf_matrix)  # Assuming this is 5 in your case\n",
    "for i in range(num_classes):\n",
    "    true_negative = np.sum(conf_matrix) - np.sum(conf_matrix[i, :]) - np.sum(conf_matrix[:, i]) + conf_matrix[i, i]\n",
    "    false_positive = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
    "    specificity_class_i = true_negative / (true_negative + false_positive) if (true_negative + false_positive) != 0 else 0\n",
    "    specificity.append(specificity_class_i)\n",
    "\n",
    "# Rest of the code remains the same\n",
    "\n",
    "# Printing results\n",
    "print(f'Specificity (per class): {np.array(specificity)}')\n",
    "print(f'Specificity (avg): {np.mean(np.array(specificity))}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T03:35:54.172795100Z",
     "start_time": "2023-12-07T03:35:54.145742200Z"
    }
   },
   "id": "573acedc6b7457f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "22988beb65dc2fea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
